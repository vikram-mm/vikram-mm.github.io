<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128477061-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-128477061-1');
</script>

  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <!-- <link rel="icon" type="image/png" href="seal_icon.png"> -->
  <title>Vikram Mandikal</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="60%" valign="middle">
              <p align="center">
                <name>Vikram Mandikal</name>
              </p>
              <p> I am an MS CS student at the University of Texas at Austin where I am a part of the <a href= "http://www.ideal.ece.utexas.edu/index.html"> IDEAL Lab</a>! I was an Applied Scientist Intern at Amazon Alexa AI over the summer of 2020 where I worked on distillation of cross-lingual language models (XLMs).
                 <!--I am looking out for exciting internship opportunities for the summer of 2020, shoot me an  <a href="mailto:vikram@cs.utexas.edu">email</a> to get in touch. -->
              </p>
              <p>Before coming to UT Austin, I completed my undergradtue studies at the <a href="http://www.nitk.ac.in/">National Institute of Technology Karnataka, Surathkal, India</a> where I graduated with a Gold medal. I worked with <a href="http://harsha-simhadri.org/"> Dr. Harsha Simhadri </a> and <a href="http://www.prateekjain.org/"> Dr. Prateek Jain </a> at <b>Microsoft Research, India</b> as a part of my undergraduate thesis. I designed a meta-learning algorithm which enables RNNs to make rolling predictions, this reduces the computational complexity and enables it to be deployed on tiny edge devices (as small as 2KB!). I also contibuted to developing resource efficient speech recognition systems, this work is currently under review at NeurIPS 2019.
              </p>
              <p>
                I spent the summer of 2018 in the beautiful city of Heidelberg under the guidance of <a href="https://hci.iwr.uni-heidelberg.de/people/fhamprec"> Prof. Fred Hamprecht </a> (and a huge shout out to <a href="https://scholar.google.de/citations?user=ZLTMBaEAAAAJ&hl=en"> Steffen Wolf</a>!). I developed a GAN framework for instance segmentation using the Mutex Watershed algorithm. I spent the summer of 2017 at the amazing <a href="http://val.serc.iisc.ernet.in/valweb/index.html">IISc</a> where I worked on spiking neural networks. I began my journey into the world of research in the summer of 2016 at IIT Gandhinagar under the guidance of <a href="https://www.iitgn.ac.in/faculty/electrical/shanmuganathan.htm">
                 Dr. Shanmuganathan Raman</a>, where I worked on unsupervised object detection.
              </p>
              <p>
                My <b>interests</b> are broadly in machine learning. I have worked on problems in the domains of speech recogintion, object detection, image segmentation, resource-constrained machine learning, medical imaging, image retrieval, spiking neural networks, keyword detection in speech, activity recognition and am looking to explore more! 
              </p>
              <p align=center>
                <a href="mailto:vikram0mm@gmail.com">Email</a> &nbsp/&nbsp
                <a href="VikramResume.pdf">Resume</a> &nbsp/&nbsp
                <!-- <a href="JonBarron-bio.txt">Biography</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <a href="http://www.github.com/vikram-mm"> Github </a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/vikram-mm/"> LinkedIn </a>
              </p>
            </td>
            <td width="40%">
              <img width="100%" src="my_photo.JPG" style="border-radius: 60%" >
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
              
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img  height='75%' width='100%' src='srnn.png'></div>
                <img height='75%' width='100%' src='srnn.png'>
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }
                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">

                <papertitle>An Approach for Multi-modal Medical Image Retrieval using Latent Dirichlet Allocation </papertitle>
             
              <br>Don 
              <a href="https://dkdennis.xyz/">Don Dennis</a>,
              <a href="https://scholar.google.com/citations?user=Yo_NxlcAAAAJ&hl=en">Durmus Alp Emre ACAR</a>,
              <strong>Vikram Mandikal</strong>,
              Vinu Sankar Sadasivan,
              <a href="http://harsha-simhadri.org/">Harsha Vardhan Simhadri</a>,
              <a href="https://scholar.google.com/citations?user=S4z3uzMAAAAJ&hl=en">Venkatesh Saligrama</a>,
              <a href="http://www.prateekjain.org/">Prateek Jain</a>,
              <br>
              <em> Conference on Neural Information Processing Systems (NeurIPS)</em>, Vancouver, Canada, 2019<i>(Poster Presentation)</i>
              <br>
              <a href="https://papers.nips.cc/paper/9451-shallow-rnn-accurate-time-series-classification-on-resource-constrained-devices" target="_blank">[Paper]</a> 
              <a href="https://papers.nips.cc/paper/9451-shallow-rnn-accurate-time-series-classification-on-resource-constrained-devices-supplemental.zip" target="_blank">[Supplemnetal]</a>
              <p>Recurrent Neural Networks (RNNs) capture long dependencies and context, and 2 hence are the key component of typical sequential data based tasks. However, the sequential nature of RNNs dictates a large inference cost for long sequences even if the hardware supports parallelization. To induce long-term dependencies, and yet admit parallelization, we introduce novel shallow RNNs. In this architecture, the first layer splits the input sequence and runs several independent RNNs. The second layer consumes the output of the first layer using a second RNN thus capturing long dependencies. We provide theoretical justification for our architecture under weak assumptions that we verify on real-world benchmarks. Furthermore, we show that for time-series classification, our technique leads to substantially improved inference time over standard RNNs without compromising accuracy. For example, we can deploy audio-keyword classification on tiny Cortex M4 devices (100MHz processor, 256KB RAM, no DSP available) which was not possible using standard RNN models. Similarly, using SRNN in the popular Listen-Attend-Spell (LAS) architecture for phoneme classification, we can reduce the lag inphoneme classification by 10-12x while maintaining state-of-the-art accuracy. </p>
              <p>
              <!-- <p>This system is the basis for "Portrait Mode" on the Google Pixel 2 smartphones</p> -->
            </td>
          </tr>    


          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img  height='95%' width='100%' src='segmentation.png'></div>
                <img height='95%' width='100%' src='image_.png'>
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }
                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">

                <papertitle>A GAN framework for Instance Segmentation using the Mutex Watershed Algorithm</papertitle>
             
              <br>
              <strong>Mandikal Vikram</strong>,
              <a href="https://scholar.google.de/citations?user=ZLTMBaEAAAAJ&hl=en">Steffen Wolf</a>,
              <br>
              <em>Smooth Games Optimization and Machine Learning Workshop, NeurIPS</em>, Montreal, 2018, <i>(Accepted for Spoltlight presentation)</i>
              <br>
              <a href="https://sgo-workshop.github.io/papers/16/sgo.pdf" target="_blank">[Paper]</a> 
              <a href="nips_sgoml_poster.pdf" target="_blank">[Poster]</a> 
              <a href="MWS_GAN.pptx">[Slides]</a> 
              <a href="https://youtu.be/VIisa42aXyU?list=PLAbhNpVZQkbs2uAc05ebwSqWh6xMRp0AX&t=4801" target="_blank">[Talk/Video]</a> 
<!--               <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">blog post</a> / -->
              
              <p> We propose a GAN loss function along with the supervised loss for training a network to produce affinities for the Mutex Watershed algorithm. We show that this method and additional auxiliary task losses improve the quality of the segmentation. We present an ablation study to show that when the images in the target domain are constrained to be discrete, adding an auxiliary task with smooth target images significantly improves the training performance and stability.</p>

              <!-- <p>This system is the basis for "Portrait Mode" on the Google Pixel 2 smartphones</p> -->
            </td>
          </tr>    
          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img  height='95%' width='95%' src='q1.png'></div>
                <img height='95%' width='95%' src='q1.png'>
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }
                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">

                <papertitle>An Approach for Multi-modal Medical Image Retrieval using Latent Dirichlet Allocation </papertitle>
             
              <br>
              <strong>Mandikal Vikram</strong>,
              <a href="https://aditya5558.github.io/">A Aditya</a>,
              Suhas B S,
              <a href="http://infotech.nitk.ac.in/faculty/sowmya-kamath-s">Sowmya Kamath</a>
              <br>
              <em>The ACM India Joint International Conference on Data Science & Management of Data (<a href="http://cods-comad.in/2019/index.html">CoDS-COMAD</a>)</em>, Kolkata, 2019 <i>(Oral Presentation)</i>
              <br>
              <a href="cods_comad_camera_ready.pdf" target="_blank">[Paper]</a> 
              <a href="https://github.com/vikram-mm/Multimodal-Image-Retrieval" target="_blank">[Code]</a>              
              <br>A short version is accepted at the <em>AI for Social Good Workshop, NeurIPS</em>, Montreal, 2018!<br>
              <a href="https://aiforsocialgood.github.io/2018/pdfs/track1/75-AIFSG_Camera_Ready(1).pdf" target="_blank">[Paper]</a> 
              <a href="https://aiforsocialgood.github.io/2018/pdfs/track1/75-poster.pdf" target="_blank">[Poster]</a>
              <p>Latent Dirichlet Allocation (LDA) based technique for encoding the visual features of the medical images along with novel early fusion and late fusion techniques to combine the textual and visual features. </p>
              <p>
              <!-- <p>This system is the basis for "Portrait Mode" on the Google Pixel 2 smartphones</p> -->
            </td>
          </tr>       
        </table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Selected Projects</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="SNN.png" alt="prl" width="160" height="160"></td>
            <td width="75%" valign="top">
              <p>
                
                <papertitle>Spiking Neural Networks</papertitle>
               
                <br>
                May - July 2017
                <br>
              <a href="https://docs.google.com/presentation/d/1e_1XjU4uafFHz_NOoMX8DCwjkSXx1uY3WxuarVZItyo/edit?usp=sharing">[PPT]</a> 
              <a href="https://github.com/vikram-mm/Spiking-Neural-Network---Theano-Framework">[Code]</a> 
                <!-- <strong>Aditya Anantharaman</strong> -->
                <p>
                  <br> It is a well-known fact that temporal processing is a key component of human perception, unfortunately, current deep learning models donot exploit this. Even though backpropagation is known to be biologically impossible, it is ubiquitous in machine learning (because it works of course!). Spiking neural networks are biologically plausible neural networks where the weight update is through the Spike Time Dependent Plasticity (STDP) instead of backpropagation.
                </p>
                
              </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img src="od.png" alt="prl" width="160" height="160"></td>
            <td width="75%" valign="top">
              <p>
                
                <papertitle>A YOLO Based Approach for Traffic Sign Detection</papertitle>
               
                <br>
                January - March 2018
                <br>
              <a href="yolo_report.pdf" target="_blank">[Report]</a> 
              <a href="https://github.com/vikram-mm/Traffic-Sign-Detection-YOLO" target="_blank">[Code]</a> 
                <!-- <strong>Aditya Anantharaman</strong> -->
                <p>
                  <br>Fine-tuned the YOLO network to localize and classify traffic signs using the Belgium Traffic Sign Dataset. Modified the loss function to differentially penalize large and small objects, thus exploiting the fact that traffic signs are generally smaller objects
                </p>
                
              </p>
            </td>
          </tr>
           <tr>
            <tr onmouseout="portrait2_stop()" onmouseover="portrait2_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image2'><img  height='95%' width='95%' src='parrot_compressed.jpg'></div>
                <img height='95%' width='95%' src='parrot.jpg'>
              </div>
              <script type="text/javascript">
                function portrait2_start() {
                  document.getElementById('portrait_image2').style.opacity = "1";
                }
                function portrait2_stop() {
                  document.getElementById('portrait_image2').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td width="75%" valign="top">
              <p>
                
                <papertitle>Parallel K-Means Clustering for Image Colour Quantization</papertitle>
               
                <br>
                September - November 2018
                <br>
              <a href="kmeans_report.pdf" target="_blank">[Report]</a> 
              <a href="https://github.com/hehaichi/Parallel-K-means" target="_blank">[Code]</a> 
                <!-- <strong>Aditya Anantharaman</strong> -->
                <p>
                  <br>K-means clustering is used image colour quantization, we show how this can be efficeiently parallelized and implement it on three platforms - OpenMP, CUDA and MPI and compare their performances.
                </p>
                
              </p>
            </td>
          </tr>
           <tr>
            <td width="25%"><img src="android-malware.jpg" alt="prl" width="160" height="160">
            <p>
              <font size="1" px="">Image Credits:</font><a href="https://arstechnica.com/information-technology/2018/01/found-new-android-malware-with-never-before-seen-spying-capabilities/"><font size="1" px=""> Link</font></a>
            </p>
            </td>
            <td width="75%" valign="top">
              <p>
                
                <papertitle>Android Malware Detection</papertitle>
                
                <br>
                Jan - Mar 2018
                <br>
              <a href="https://github.com/vikram-mm/Android-Malware-Detection" target="_blank">[Code]</a> 
                <!-- <strong>Aditya Anantharaman</strong> -->
                <p>
                  <br> Classification of android apps done based on pseudo-dynamic analysis of system API Call sequences. Developed a Deep Autoencoder model for feature compression along with a CNN and RNN model.
                </p>
                
              </p>
            </td>
          </tr>
         
        </table>
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="pacman.jpg" alt="pacman" width="160" height="160"></td>
            <td width="75%" valign="center">
              <p>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">
                  <papertitle>CS188 - Fall 2010 (GSI)</papertitle>
                </a>
                <br>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">
                  <papertitle>CS188 - Spring 2011 (GSI)</papertitle>
                </a>
                <br>
              </p>
            </td>
          </tr>
        </table> -->


</body>

</html>

